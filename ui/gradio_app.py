# app/ui/gradio_app.py
#
# Gradio UI for the Tech Explanation Service.
# This module defines an interactive web interface that allows users
# to input a technical topic and receive an AI-generated explanation.
# The UI delegates all business logic to the TechExplanationService.

import gradio as gr

from app.services.tech_explanation_service import TechExplanationService


# ------------------------------------------------------------------
# Service initialization
# ------------------------------------------------------------------
# The service wraps the LCEL chain and exposes a simple application API.
service = TechExplanationService()


# ------------------------------------------------------------------
# Streaming callback 
# ------------------------------------------------------------------
def explain_topic_stream(topic: str):
    # Stream explanation chunk by chunk using LCEL's .stream().
    if not topic or not topic.strip():
        yield "Please enter a technical topic."
        return

    # LCEL chain returns a generator of partial outputs
    for chunk in service.explain_stream(topic.strip()):
        yield chunk
# ------------------------------------------------------------------
# Explain topic with history callback
# ------------------------------------------------------------------
def explain_topic_with_history(topic: str, history):
    if not topic.strip():
        return history, "Please enter a technical topic."

    explanation = service.explain(topic.strip())
    history = service.add_to_history(topic.strip(), explanation, history)

    formatted_output = "\n\n".join([f"**Topic:** {t}\n{e}" for t, e in history])
    return history, formatted_output
    

# ------------------------------------------------------------------
# Gradio interface definition
# ------------------------------------------------------------------
with gr.Blocks(title="Tech Explanation Service") as demo:
    gr.Markdown(
        """
        # Tech Explanation Service

        Enter a technical topic and receive a clear, structured explanation
        generated by an AI model.

        This demo showcases a **LangChain LCEL-based architecture** with a
        clean separation between UI, service layer, and LLM logic.
        """
    )

    # State for maintaining history
    history_state = gr.State([])

    with gr.Column():
        # Input
        topic_input = gr.Textbox(
            label="Enter technical topic",
            placeholder="Type a topic... e.g. Docker",
            lines=1,
        )

        # Chat-like output box
        output_box = gr.Textbox(
            label="Explanation",
            lines=15,
            max_lines=None,
            interactive=False,
        )
    
        explain_button = gr.Button("Explain")

    # ------------------------------------------------------------------
    # Events
    # ------------------------------------------------------------------
    # Trigger explanation on button click
    explain_button.click(
        fn=explain_topic_with_history,
        inputs=[topic_input, history_state],
        outputs=[history_state, output_box],
    )

    # Trigger explanation when pressing Enter in the textbox
    topic_input.submit(
        fn=explain_topic_with_history,
        inputs=[topic_input, history_state],
        outputs=[history_state, output_box],
    )


