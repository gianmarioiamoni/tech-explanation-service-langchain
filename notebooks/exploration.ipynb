{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb3e9ff5",
   "metadata": {},
   "source": [
    "# Tech Explanation Service - Exploration Notebook\n",
    "\n",
    "This notebook is designed for **interactive exploration and testing** of the Tech Explanation Service.\n",
    "\n",
    "## Purpose\n",
    "- Test `ChatPromptTemplate` with few-shot examples\n",
    "- Verify output quality and style\n",
    "- Experiment with different technical topics\n",
    "- Serve as a playground before integrating changes into the service layer\n",
    "\n",
    "## Prerequisites\n",
    "- ✅ Ensure you're using the `tech-explain` kernel (Python 3.11)\n",
    "- ✅ Make sure `.env` file exists with `OPENAI_API_KEY` set\n",
    "- ✅ Run cells in order\n",
    "\n",
    "## Structure\n",
    "1. **Setup & Imports**: Configure environment and import modules\n",
    "2. **Initialize Service**: Create service and prompt instances\n",
    "3. **Explore Prompt**: Inspect formatted messages sent to the LLM\n",
    "4. **Test Output**: Generate a single explanation\n",
    "5. **Multiple Topics**: Batch test with various topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67c1f1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Project root added to path: /Users/gianmarioiamoni/PROGRAMMAZIONE/Projects/tech-explanation-service-langchain\n",
      "✓ OPENAI_API_KEY is set\n",
      "✓ All imports successful\n",
      "=== Formatted Messages ===\n",
      "SystemMessage: \n",
      "        You are a senior technical assistant.\n",
      "        Provide clear, structured, and concise technical explanations.\n",
      "        Avoid marketing language and unnecessary verbosity.\n",
      "        \n",
      "\n",
      "HumanMessage: Question: What is LangChain?\n",
      "\n",
      "AIMessage: Answer: LangChain is a Python framework designed to simplify the development of applications powered by large language models, providing abstractions for prompt composition, chains, and agents.\n",
      "\n",
      "HumanMessage: Question: What is the purpose of few-shot prompting?\n",
      "\n",
      "AIMessage: Answer: Few-shot prompting guides a language model by providing example input-output pairs, improving consistency, structure, and response quality.\n",
      "\n",
      "HumanMessage: Explain Few-Shot Prompting in LangChain\n",
      "\n",
      "=== LLM Explanation Output ===\n",
      "Few-shot prompting in LangChain involves providing a language model with a set of example input-output pairs to guide its responses. This technique helps the model understand the desired format and context, improving the quality and relevance of its outputs. In LangChain, few-shot prompting can be implemented by defining a prompt template that includes these examples, allowing the model to learn from them and generate more accurate and contextually appropriate responses. This approach is particularly useful when you want the model to perform specific tasks or follow a particular style without extensive retraining.\n",
      "\n",
      "--- Topic: ChatOpenAI class ---\n",
      "The `ChatOpenAI` class is part of the LangChain framework, designed to facilitate interactions with OpenAI's chat-based language models. Here are its key features and functionalities:\n",
      "\n",
      "1. **Initialization**: The class is initialized with parameters such as the model name, temperature, and API key, allowing customization of the model's behavior and access.\n",
      "\n",
      "2. **Temperature Control**: The `temperature` parameter adjusts the randomness of the model's responses. A lower temperature results in more deterministic outputs, while a higher temperature increases variability.\n",
      "\n",
      "3. **Message Handling**: The class manages the formatting and sending of messages to the model, handling both user inputs and model responses.\n",
      "\n",
      "4. **Response Parsing**: It processes the model's responses, converting them into a usable format for further application logic.\n",
      "\n",
      "5. **Integration**: The class is designed to integrate seamlessly with other components of the LangChain framework, such as chains and agents, to build complex applications.\n",
      "\n",
      "Overall, the `ChatOpenAI` class abstracts the complexities of interacting with OpenAI's chat models, making it easier to develop applications that leverage conversational AI.\n",
      "\n",
      "--- Topic: System, Human, AI Messages ---\n",
      "System, Human, and AI messages are components used in conversational AI systems to structure interactions:\n",
      "\n",
      "1. **System Messages**: These are instructions or guidelines provided to the AI model to set the context or behavior for the conversation. They help define the role of the AI and establish the tone or rules for the interaction.\n",
      "\n",
      "2. **Human Messages**: These are inputs from the user or human participant in the conversation. They represent the questions, commands, or statements that the user wants the AI to respond to or act upon.\n",
      "\n",
      "3. **AI Messages**: These are the responses generated by the AI model based on the system instructions and human inputs. They aim to address the user's queries or continue the conversation in a coherent and contextually appropriate manner.\n",
      "\n",
      "Together, these message types facilitate structured and meaningful interactions between users and AI systems.\n",
      "\n",
      "--- Topic: PromptTemplate class ---\n",
      "The `PromptTemplate` class in LangChain is used to create structured prompts for language models. It allows you to define a template with placeholders that can be dynamically filled with specific values at runtime. This helps in generating consistent and reusable prompts for different tasks. The class typically includes:\n",
      "\n",
      "1. **Template Definition**: A string with placeholders (e.g., `{input}`) that specify where dynamic content will be inserted.\n",
      "2. **Input Variables**: A list of variable names that correspond to the placeholders in the template.\n",
      "3. **Rendering**: A method to fill in the template with actual values, producing a complete prompt ready for use with a language model.\n",
      "\n",
      "This approach ensures that prompts are both flexible and maintainable, facilitating experimentation and iteration in language model applications.\n"
     ]
    }
   ],
   "source": [
    "# notebooks/exploration.ipynb\n",
    "#\n",
    "# This notebook is intended for interactive exploration and testing of the\n",
    "# Tech Explanation Service prompts and LLM responses.\n",
    "#\n",
    "# Responsibilities:\n",
    "# - Test ChatPromptTemplate with few-shot examples\n",
    "# - Verify output quality and style\n",
    "# - Experiment with different topics\n",
    "# - Serve as a playground before integrating changes into the service layer\n",
    "\n",
    "# --- Setup Python path ---\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to Python path to enable imports from 'app' package\n",
    "project_root = Path().absolute().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# --- Setup environment ---\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables (.env) for OpenAI API key\n",
    "load_dotenv()\n",
    "assert os.getenv(\"OPENAI_API_KEY\"), \"OPENAI_API_KEY must be set\"\n",
    "\n",
    "print(f\"✓ Project root added to path: {project_root}\")\n",
    "print(f\"✓ OPENAI_API_KEY is set\")\n",
    "\n",
    "# --- Import service and prompt ---\n",
    "from app.services.tech_explanation_service import TechExplanationService\n",
    "from app.prompts.tech_explanation_prompt import build_tech_explanation_prompt\n",
    "\n",
    "print(\"✓ All imports successful\")\n",
    "\n",
    "# --- Initialize service and prompt ---\n",
    "service = TechExplanationService()\n",
    "prompt = build_tech_explanation_prompt()\n",
    "\n",
    "# --- Explore prompt messages ---\n",
    "topic_example = \"Few-Shot Prompting in LangChain\"\n",
    "\n",
    "# Format the messages to see what will be sent to the LLM\n",
    "messages = prompt.format_messages(topic=topic_example)\n",
    "print(\"=== Formatted Messages ===\")\n",
    "for msg in messages:\n",
    "    print(f\"{type(msg).__name__}: {msg.content}\\n\")\n",
    "\n",
    "# --- Test the service output ---\n",
    "explanation = service.explain(topic_example)\n",
    "print(\"=== LLM Explanation Output ===\")\n",
    "print(explanation)\n",
    "\n",
    "# --- Experiment with multiple topics ---\n",
    "topics = [\n",
    "    \"ChatOpenAI class\",\n",
    "    \"System, Human, AI Messages\",\n",
    "    \"PromptTemplate class\"\n",
    "]\n",
    "\n",
    "for t in topics:\n",
    "    print(f\"\\n--- Topic: {t} ---\")\n",
    "    result = service.explain(t)\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9570fbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing service and prompt...\n",
      "✓ Service initialized (Model: gpt-4o, Temperature: 0.2)\n",
      "\n",
      "============================================================\n",
      "FORMATTED MESSAGES\n",
      "============================================================\n",
      "\n",
      "1. SystemMessage\n",
      "------------------------------------------------------------\n",
      "\n",
      "        You are a senior technical assistant.\n",
      "        Provide clear, structured, and concise technical explanations.\n",
      "        Avoid marketing language and unnecessary verbosity.\n",
      "        \n",
      "\n",
      "2. HumanMessage\n",
      "------------------------------------------------------------\n",
      "Question: What is LangChain?\n",
      "\n",
      "3. AIMessage\n",
      "------------------------------------------------------------\n",
      "Answer: LangChain is a Python framework designed to simplify the development of applications powered by large language models, providing abstractions for prompt composition, chains, and agents.\n",
      "\n",
      "4. HumanMessage\n",
      "------------------------------------------------------------\n",
      "Question: What is the purpose of few-shot prompting?\n",
      "\n",
      "5. AIMessage\n",
      "------------------------------------------------------------\n",
      "Answer: Few-shot prompting guides a language model by providing example input-output pairs, improving consistency, structure, and response quality.\n",
      "\n",
      "6. HumanMessage\n",
      "------------------------------------------------------------\n",
      "Explain Few-Shot Prompting in LangChain\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c90e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calling LLM API...\n",
      "============================================================\n",
      "LLM EXPLANATION OUTPUT\n",
      "============================================================\n",
      "Few-shot prompting in LangChain involves providing a language model with a set of example input-output pairs to guide its responses. This technique helps the model understand the desired format, tone, or type of response expected for a given task. In LangChain, few-shot prompting can be implemented by defining a prompt template that includes these examples, which are then used to generate more accurate and contextually relevant outputs. This approach is particularly useful for tasks where the model needs to adapt to specific styles or formats without extensive retraining.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78848d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TESTING MULTIPLE TOPICS\n",
      "============================================================\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Topic: ChatOpenAI class\n",
      "────────────────────────────────────────────────────────────\n",
      "The `ChatOpenAI` class is part of the LangChain framework and is used to interact with OpenAI's chat-based language models. It provides a structured way to send messages to these models and receive responses, facilitating the development of applications that require conversational AI capabilities. Key features include:\n",
      "\n",
      "1. **Initialization**: The class is initialized with parameters such as the model name, temperature (to control randomness), and API key for authentication.\n",
      "\n",
      "2. **Message Handling**: It allows for the creation and management of chat messages, supporting both user and system messages to guide the conversation context.\n",
      "\n",
      "3. **Response Generation**: The class handles sending messages to the OpenAI API and retrieving responses, abstracting the API interaction details.\n",
      "\n",
      "4. **Customization**: Users can customize the behavior of the model by adjusting parameters like temperature, max tokens, and more, to fit specific application needs.\n",
      "\n",
      "Overall, the `ChatOpenAI` class streamlines the process of integrating OpenAI's chat models into applications, focusing on ease of use and flexibility.\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Topic: System, Human, AI Messages\n",
      "────────────────────────────────────────────────────────────\n",
      "In the context of conversational AI, particularly when using frameworks like OpenAI's API, messages are categorized into three types: System, Human, and AI messages. Each serves a distinct role in guiding and structuring the interaction:\n",
      "\n",
      "1. **System Messages**:\n",
      "   - **Purpose**: Set the tone, style, or specific instructions for the AI's behavior throughout the conversation.\n",
      "   - **Example**: \"You are a helpful assistant that provides concise technical explanations.\"\n",
      "\n",
      "2. **Human Messages**:\n",
      "   - **Purpose**: Represent the input or queries from the user interacting with the AI.\n",
      "   - **Example**: \"Can you explain how neural networks work?\"\n",
      "\n",
      "3. **AI Messages**:\n",
      "   - **Purpose**: Contain the responses generated by the AI based on the system instructions and human inputs.\n",
      "   - **Example**: \"Neural networks are computational models inspired by the human brain, consisting of layers of interconnected nodes that process data.\"\n",
      "\n",
      "These message types help structure the dialogue, ensuring clarity and coherence in AI-driven interactions.\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Topic: PromptTemplate class\n",
      "────────────────────────────────────────────────────────────\n",
      "The `PromptTemplate` class in LangChain is used to create structured prompts for language models. It allows you to define a template with placeholders that can be dynamically filled with specific values at runtime. This helps in generating consistent and reusable prompts for various tasks.\n",
      "\n",
      "Key features of the `PromptTemplate` class include:\n",
      "\n",
      "1. **Template Definition**: You can define a prompt with placeholders, which are later replaced with actual values.\n",
      "\n",
      "2. **Dynamic Filling**: At runtime, you can provide specific values to fill in the placeholders, allowing for flexible prompt generation.\n",
      "\n",
      "3. **Reusability**: Once defined, a `PromptTemplate` can be reused across different tasks or models, ensuring consistency in prompt structure.\n",
      "\n",
      "4. **Parameter Validation**: The class can validate that all required placeholders are provided with values, reducing errors in prompt generation.\n",
      "\n",
      "Overall, the `PromptTemplate` class streamlines the process of creating and managing prompts for language models, enhancing both efficiency and reliability.\n",
      "\n",
      "============================================================\n",
      "All tests completed!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tech-explain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
